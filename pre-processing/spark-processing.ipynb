{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e60b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda3e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/openjdk@11\n",
      "findspark initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load AWS keys and S3 warehouse location\n",
    "load_dotenv()\n",
    "\n",
    "# Set Spark & Java env\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/homebrew/Cellar/apache-spark/3.5.4/libexec\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "#os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@11\"\n",
    "java_home = subprocess.getoutput(\"dirname $(dirname $(which java))\")\n",
    "print(java_home)\n",
    "os.environ[\"JAVA_HOME\"] = java_home\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "os.environ[\"aws.region\"] = \"us-east-1\"\n",
    "\n",
    "\n",
    "# Use Iceberg + AWS Glue with Spark runtime 3.5\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    \"--packages \"\n",
    "    \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,\"\n",
    "    \"software.amazon.awssdk:glue:2.20.128,\"\n",
    "    \"software.amazon.awssdk:s3:2.20.128,\"\n",
    "    \"software.amazon.awssdk:sts:2.20.128,\"\n",
    "    \"software.amazon.awssdk:kms:2.20.128,\"\n",
    "    \"software.amazon.awssdk:dynamodb:2.20.128,\"\n",
    "    \"org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell\"\n",
    ")\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "#    \"--packages \"\n",
    "#    \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,\"\n",
    "#    \"org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell\"\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "# Append Spark Python path\n",
    "sys.path.append(\"/opt/homebrew/Cellar/apache-spark/3.5.4/libexec/python/lib\")\n",
    "\n",
    "# Initialize Spark via findspark\n",
    "findspark.init()\n",
    "print(\"findspark initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94df3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/homebrew/Cellar/apache-spark/3.5.4/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/sarthak/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/sarthak/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#glue added as a dependency\n",
      "software.amazon.awssdk#s3 added as a dependency\n",
      "software.amazon.awssdk#sts added as a dependency\n",
      "software.amazon.awssdk#kms added as a dependency\n",
      "software.amazon.awssdk#dynamodb added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c7e4bb91-6d31-42c8-ba0e-17b9f04c4380;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central\n",
      "\tfound software.amazon.awssdk#glue;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#aws-json-protocol;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#aws-core;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#regions;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#utils;2.20.128 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#sdk-core;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#endpoints-spi;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#profiles;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#json-utils;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#third-party-jackson-core;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#auth;2.20.128 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#protocol-core;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#apache-client;2.20.128 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound software.amazon.awssdk#netty-nio-client;2.20.128 in central\n",
      "\tfound io.netty#netty-codec-http;4.1.94.Final in central\n",
      "\tfound io.netty#netty-common;4.1.94.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.94.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.94.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.94.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.94.Final in central\n",
      "\tfound io.netty#netty-handler;4.1.94.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.94.Final in central\n",
      "\tfound io.netty#netty-codec-http2;4.1.94.Final in central\n",
      "\tfound io.netty#netty-transport-classes-epoll;4.1.94.Final in central\n",
      "\tfound software.amazon.awssdk#s3;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#aws-xml-protocol;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#aws-query-protocol;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#arns;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#crt-core;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#sts;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#kms;2.20.128 in central\n",
      "\tfound software.amazon.awssdk#dynamodb;2.20.128 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 454ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tio.netty#netty-buffer;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-codec-http;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-codec-http2;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-transport-classes-epoll;4.1.94.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.94.Final from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#apache-client;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#arns;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#auth;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#aws-core;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#aws-json-protocol;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#aws-query-protocol;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#aws-xml-protocol;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#crt-core;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#dynamodb;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#endpoints-spi;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#glue;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#json-utils;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#kms;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#netty-nio-client;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#profiles;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#protocol-core;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#regions;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#s3;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#sdk-core;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#sts;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#third-party-jackson-core;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.20.128 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   46  |   0   |   0   |   0   ||   46  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c7e4bb91-6d31-42c8-ba0e-17b9f04c4380\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 46 already retrieved (0kB/7ms)\n",
      "25/04/20 17:53:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started successfully!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergGlueCatalogSetup\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.catalog.my_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.my_catalog.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.my_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "    .config(\"spark.sql.catalog.my_catalog.warehouse\", os.environ.get(\"s3_location\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ.get(\"AWS_ACCESS_KEY_ID\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session started successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5996943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/20 17:39:17 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a better way\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS my_catalog.nonprofit_data_explorer.bmo_table (\n",
    "    EIN STRING,\n",
    "    NAME STRING,\n",
    "    ICO STRING,\n",
    "    STREET STRING,\n",
    "    CITY STRING,\n",
    "    STATE STRING,\n",
    "    ZIP STRING,\n",
    "    GROUP STRING,\n",
    "    SUBSECTION STRING,\n",
    "    AFFILIATION STRING,\n",
    "    CLASSIFICATION STRING,\n",
    "    RULING STRING,\n",
    "    DEDUCTIBILITY STRING,\n",
    "    FOUNDATION STRING,\n",
    "    ACTIVITY STRING,\n",
    "    ORGANIZATION STRING,\n",
    "    STATUS STRING,\n",
    "    TAX_PERIOD STRING,\n",
    "    ASSET_CD STRING,\n",
    "    INCOME_CD STRING,\n",
    "    FILING_REQ_CD STRING,\n",
    "    PF_FILING_REQ_CD STRING,\n",
    "    ACCT_PD STRING,\n",
    "    ASSET_AMT STRING,\n",
    "    INCOME_AMT STRING,\n",
    "    REVENUE_AMT STRING,\n",
    "    NTEE_CD STRING,\n",
    "    SORT_NAME STRING\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (STATE)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc71350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----------+\n",
      "|           namespace|tableName|isTemporary|\n",
      "+--------------------+---------+-----------+\n",
      "|nonprofit_data_ex...|bmo_table|      false|\n",
      "+--------------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN my_catalog.nonprofit_data_explorer\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe24a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/20 17:54:02 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "25/04/20 17:54:04 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------------------+--------------------+--------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "|      EIN|                NAME|                ICO|              STREET|          CITY|STATE|       ZIP|GROUP|SUBSECTION|AFFILIATION|CLASSIFICATION|RULING|DEDUCTIBILITY|FOUNDATION| ACTIVITY|ORGANIZATION|STATUS|TAX_PERIOD|ASSET_CD|INCOME_CD|FILING_REQ_CD|PF_FILING_REQ_CD|ACCT_PD|ASSET_AMT|INCOME_AMT|REVENUE_AMT|NTEE_CD|           SORT_NAME|\n",
      "+---------+--------------------+-------------------+--------------------+--------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "|010215913|BUCK MEMORIAL LIB...|        % TREASURER|             MAIN ST|     BUCKSPORT|   ME|04416-0000| 0000|        03|          3|          3000|195006|            1|        15|061000000|           1|    01|    202312|       6|        4|           01|               0|     12|  2571599|    426391|     234509|   NULL|                NULL|\n",
      "|010244457|NEW ENGLAND ELECT...|               NULL|            PO BOX A| KENNEBUNKPORT|   ME|04046-1690| 0000|        03|          3|          1000|194801|            1|        16|062060000|           1|    01|    202312|       8|        6|           01|               0|     12| 10980223|   2428508|    1681938|   NULL|                NULL|\n",
      "|010319671|WELLINGTON EVANGE...|               NULL|               LOCAL|    WELLINGTON|   ME|04990-0000| 0000|        03|          3|          1000|197303|            1|        10|001000000|           1|    01|      NULL|       0|        0|           06|               0|     12|     NULL|      NULL|       NULL|   NULL|                NULL|\n",
      "|010329152|BUCKSPORT BIBLE C...|               NULL|            PO BOX Q|     BUCKSPORT|   ME|04416-1217| 0000|        03|          3|          7000|199512|            1|        10|001029030|           1|    01|      NULL|       0|        0|           06|               0|     08|     NULL|      NULL|       NULL|   X20Z|                NULL|\n",
      "|010339532|POPHAM BEACH ASSO...|    % SHELTON WHITE|              PO BOX|    PHIPPSBURG|   ME|04562-0000| 0000|        03|          3|          2000|199306|            1|        15|061319000|           5|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|   NULL|                NULL|\n",
      "|010346158|TACOMA LAKES ASSO...|     % JUDY BOURGET|     COMMUNITY DRIVE|    LITCHFIELD|   ME|04350-0000| 0000|        03|          3|          2000|201601|            1|        16|297351000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    C32|                NULL|\n",
      "|010351827|      HELEN R COE TR|      % PETER MALIA|CO MICHAEL FRIEDM...|      BRIDGTON|   ME|04009-0000| 0000|        03|          3|          1000|197712|            1|        04|040119602|           2|    01|    202403|       6|        5|           00|               1|     03|  2205920|    849132|       NULL|   NULL|                NULL|\n",
      "|010354589|EASTPORT HEALTH C...|               NULL|            PO BOX H|      EASTPORT|   ME|04631-0909| 0000|        03|          3|          1000|197802|            1|        15|179465154|           1|    01|    202306|       7|        7|           01|               0|     06|  7016159|   7262032|    7223608|   E320|                NULL|\n",
      "|010354783|BUSTINS ISLAND MA...|      % LYN MCELWEE|    GENERAL DELIVERY|BUSTINS ISLAND|   ME|04013-9999| 0000|        03|          3|          2000|197806|            1|        15|060061062|           1|    01|    202408|       0|        0|           02|               0|     08|        0|         0|          0|   NULL|                NULL|\n",
      "|010370171|FIRST PENTECOSTAL...|               NULL|               LOCAL|       KINGMAN|   ME|04451-0000| 0000|        03|          3|          7000|198012|            1|        10|001007029|           5|    01|      NULL|       0|        0|           07|               0|     12|     NULL|      NULL|       NULL|   NULL|                NULL|\n",
      "|010377246|NEW HOPE FOR WOME...|               NULL|            PO BOX A|      ROCKLAND|   ME|04841-0733| 0000|        03|          3|          1000|198111|            1|        15|319569431|           1|    01|    202309|       6|        6|           01|               0|     09|  2154861|   2426034|    2419175|   P430|                NULL|\n",
      "|010381834|EDDINGTON SALMON ...|               NULL|              PO BOX|        BREWER|   ME|04412-0000| 0000|        07|          3|          1000|198308|            2|        00|998000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|   NULL|                NULL|\n",
      "|010400759|PHILLIPS PUBLIC L...|               NULL|            PO BOX O|      PHILLIPS|   ME|04966-1514| 0000|        03|          3|          2300|202204|            1|        15|061000000|           1|    01|    202312|       4|        3|           01|               0|     12|   355310|     59556|      59556|    B11|                NULL|\n",
      "|010408548|SUNSET CEMETERY A...|% LARRY W LIGHTBODY|        FAHI POND RD|   NORTH ANSON|   ME|04958-0000| 0000|        13|          3|          1000|198512|            2|        00|900000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|   NULL|                NULL|\n",
      "|010419333|THE MOONSPRING HE...|               NULL|     MORGAN BAY ROAD|         SURRY|   ME|04684-0000| 0000|        03|          3|          7000|198712|            1|        10|001000000|           1|    01|      NULL|       0|        0|           06|               0|     12|     NULL|      NULL|       NULL|   NULL|                NULL|\n",
      "|010421806|THE BILL AND JOAN...|    % DEXTER ENTRPS|CO DEXTER ENTRPS ...|      PORTLAND|   ME|04101-0000| 0000|        03|          3|          1000|198705|            1|        04|602000000|           1|    01|    202312|       8|        7|           00|               1|     12| 30941597|   5833594|       NULL|   NULL|                NULL|\n",
      "|010424837|GEORGES RIVER LAN...|               NULL|            PO BOX B|      ROCKLAND|   ME|04841-0734| 0000|        03|          3|          1200|198707|            1|        15|350352354|           1|    01|    202312|       7|        5|           01|               0|     12|  7455681|    950725|     916473|   C340|                NULL|\n",
      "|010458230|HOUSEL-RYAN-SHELD...|               NULL|           MEADOW RD|   SANDY POINT|   ME|04972-0000| 0000|        03|          3|          1000|199303|            1|        04|355000000|           1|    01|    202312|       5|        1|           00|               1|     12|   723031|       335|       NULL|   D34Z|MEADOW FARMS HRS ...|\n",
      "|010461676|ISLAND FALLS HIST...|        % GREG RYAN|    NINA SAWYER LANE|  ISLAND FALLS|   ME|04747-0000| 0000|        03|          3|          1000|201408|            1|        15|062000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    A80|                NULL|\n",
      "|010471985|BROADREACH FAMILY...|% RUTH H SOUTHWORTH|     ONE PORTLAND SQ|      PORTLAND|   ME|04101-4057| 0000|        03|          3|          1000|199212|            1|        11|031032000|           1|    01|    202209|       0|        0|           01|               0|     09|        0|         0|     -25693|    B21|                NULL|\n",
      "+---------+--------------------+-------------------+--------------------+--------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_path = \"s3a://nonprofit-explorer/raw_data/\"\n",
    "\n",
    "# Load CSVs from S3\n",
    "df = spark.read.option(\"header\", True).csv(s3_path)\n",
    "\n",
    "# Show data\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd23c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# look for a better way\n",
    "# Optional: balance your write to reduce small files\n",
    "#df = df.repartition(\"STATE\")\n",
    "\n",
    "df = df.repartition(8)  # Optional, for performance/file-size control\n",
    "\n",
    "# Append to your existing Iceberg table\n",
    "df.writeTo(\"my_catalog.nonprofit_data_explorer.bmo_table\").append()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e6102",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session started successfully!\")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4111329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/19 14:30:51 WARN HadoopTableOperations: Error reading version hint file s3a://nonprofit-explorer/nonprofit/bmo/metadata/version-hint.text\n",
      "java.io.FileNotFoundException: No such file or directory: s3a://nonprofit-explorer/nonprofit/bmo/metadata/version-hint.text\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3185)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.extractOrFetchSimpleFileStatus(S3AFileSystem.java:4903)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.open(S3AFileSystem.java:1200)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.open(S3AFileSystem.java:1178)\n",
      "\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.findVersion(HadoopTableOperations.java:318)\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.refresh(HadoopTableOperations.java:104)\n",
      "\tat org.apache.iceberg.BaseTransaction.lambda$commitReplaceTransaction$1(BaseTransaction.java:368)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196)\n",
      "\tat org.apache.iceberg.BaseTransaction.commitReplaceTransaction(BaseTransaction.java:365)\n",
      "\tat org.apache.iceberg.BaseTransaction.commitTransaction(BaseTransaction.java:314)\n",
      "\tat org.apache.iceberg.CommitCallbackTransaction.commitTransaction(CommitCallbackTransaction.java:126)\n",
      "\tat org.apache.iceberg.spark.source.StagedSparkTable.commitStagedChanges(StagedSparkTable.java:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:585)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:578)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:572)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:186)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:221)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.runCommand(DataFrameWriterV2.scala:201)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.internalReplace(DataFrameWriterV2.scala:213)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.createOrReplace(DataFrameWriterV2.scala:135)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/04/19 14:30:51 WARN HadoopTableOperations: Error reading version hint file s3a://nonprofit-explorer/nonprofit/bmo/metadata/version-hint.text\n",
      "java.io.FileNotFoundException: No such file or directory: s3a://nonprofit-explorer/nonprofit/bmo/metadata/version-hint.text\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3185)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.extractOrFetchSimpleFileStatus(S3AFileSystem.java:4903)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.open(S3AFileSystem.java:1200)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.open(S3AFileSystem.java:1178)\n",
      "\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.findVersion(HadoopTableOperations.java:318)\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.refresh(HadoopTableOperations.java:104)\n",
      "\tat org.apache.iceberg.hadoop.HadoopTableOperations.current(HadoopTableOperations.java:84)\n",
      "\tat org.apache.iceberg.BaseTransaction.lambda$commitReplaceTransaction$1(BaseTransaction.java:377)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203)\n",
      "\tat org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196)\n",
      "\tat org.apache.iceberg.BaseTransaction.commitReplaceTransaction(BaseTransaction.java:365)\n",
      "\tat org.apache.iceberg.BaseTransaction.commitTransaction(BaseTransaction.java:314)\n",
      "\tat org.apache.iceberg.CommitCallbackTransaction.commitTransaction(CommitCallbackTransaction.java:126)\n",
      "\tat org.apache.iceberg.spark.source.StagedSparkTable.commitStagedChanges(StagedSparkTable.java:34)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:585)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:578)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:572)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:186)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:221)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.runCommand(DataFrameWriterV2.scala:201)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.internalReplace(DataFrameWriterV2.scala:213)\n",
      "\tat org.apache.spark.sql.DataFrameWriterV2.createOrReplace(DataFrameWriterV2.scala:135)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "df.writeTo(\"my_catalog.nonprofit.bmo\") \\\n",
    "  .partitionedBy(\"STATE\") \\\n",
    "  .using(\"iceberg\") \\\n",
    "  .createOrReplace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907cc56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already stopped\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "    print(\"stopped\")\n",
    "except:\n",
    "    print(\"already stopped\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6513313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://nonprofit-explorer/\n"
     ]
    }
   ],
   "source": [
    "print(spark.conf.get(\"spark.sql.catalog.my_catalog.warehouse\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5bc79a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "|      EIN|                NAME|                 ICO|              STREET|        CITY|STATE|       ZIP|GROUP|SUBSECTION|AFFILIATION|CLASSIFICATION|RULING|DEDUCTIBILITY|FOUNDATION| ACTIVITY|ORGANIZATION|STATUS|TAX_PERIOD|ASSET_CD|INCOME_CD|FILING_REQ_CD|PF_FILING_REQ_CD|ACCT_PD|ASSET_AMT|INCOME_AMT|REVENUE_AMT|NTEE_CD|           SORT_NAME|\n",
      "+---------+--------------------+--------------------+--------------------+------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "|300286540| MARINE CORPS LEAGUE|    % DAVID S ROGERS|       504 N SPUR DR|      PAYSON|   AZ|85541-3746| 0955|        04|          9|          3000|194607|            1|        00|908279265|           5|    01|    202406|       0|        0|           02|               0|     06|        0|         0|          0|   NULL|928 MCL RIM COUNT...|\n",
      "|311668274|VILLAGE PARK BAPT...|                NULL|        PO BOX 20413|      SEDONA|   AZ|86341-0413| 0000|        03|          3|          1000|200003|            1|        10|000000000|           1|    01|      NULL|       0|        0|           06|               0|     12|     NULL|      NULL|       NULL|    X21|                NULL|\n",
      "|263671941|CHANGING LIVES AR...|         % LYLE CLAW|      1370 LYNDA AVE|   CLARKDALE|   AZ|86324-3271| 0000|        03|          3|          1000|201004|            1|        15|000000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    P99|                NULL|\n",
      "|274797792|CARE FOR CYCLING INC|% RUSING & LOPEZ ...|6363 N SWAN RD ST...|      TUCSON|   AZ|85718-3637| 0000|        03|          3|          2100|201108|            1|        15|000000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    N60|                NULL|\n",
      "|274034997|WAT LAO THAMMARAM...|% BANDITH PHOLPHI...|     9601 N 16TH AVE|     PHOENIX|   AZ|85021-2126| 0000|        03|          3|          7000|201507|            1|        10|000000000|           1|    01|    202412|       0|        0|           06|               0|     12|        0|         0|          0|    X50|                NULL|\n",
      "|273390760|  MEDICINE DOG ARENA|      % MICHAEL FORD|  471 S TOWHEE RIDGE|     KINGMAN|   AZ|86401-4885| 0000|        03|          3|          1000|201307|            1|        15|000000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    D99|                NULL|\n",
      "|274550481|COCHISE COUNTY SA...|    % URSULA RITCHEY|2643 FAR HORIZON WAY|SIERRA VISTA|   AZ|85635-5683| 0000|        03|          3|          1000|201709|            1|        16|000000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    M23|                NULL|\n",
      "|202990000|MARANA HEALTH CEN...|   % CLARENCE VATNEY|          PO BOX 188|      MARANA|   AZ|85653-0188| 0000|        03|          3|          1000|200801|            1|        17|000000000|           1|    01|    202306|       5|        4|           01|               0|     06|   807816|    231135|     123217|   E122|                NULL|\n",
      "|320035793|VETERANS FIRST LI...|      % JOAN E SISCO|8433 N BLACK CANY...|     PHOENIX|   AZ|85021-4859| 0000|        03|          3|          1200|200307|            1|        15|000000000|           1|    01|    202112|       5|        4|           01|               0|     12|   559134|    185583|     185583|    W12|                NULL|\n",
      "|205937475|ROOSEVELT ROW COM...|        % GREG ESSER|  922 N ROOSEVELT ST|     PHOENIX|   AZ|85004-0000| 0000|        03|          3|          1000|200707|            1|        15|000000000|           1|    01|    202312|       4|        5|           01|               0|     12|   396480|    753155|     753155|    S30|                NULL|\n",
      "|263084550|HELPING HANDS FOR...|        % ERIC SNELZ|   326 E CORONADO RD|     PHOENIX|   AZ|85004-1749| 0000|        03|          3|          1000|200812|            1|        15|000000000|           1|    01|    202312|       3|        4|           01|               0|     12|    44031|    268917|     268917|    P20|                NULL|\n",
      "|237161064|ARIZONA SECTION S...|    % WILLIAM SOMERS|    1064 E LOWELL ST|      TUCSON|   AZ|85721-0001| 0000|        03|          3|          1000|201512|            1|        16|059000000|           1|    01|    202312|       0|        0|           02|               0|     12|        0|         0|          0|    C34|                NULL|\n",
      "|203237256|TUCSON CHILDRENS ...|     % BARBARA RICCA|         PO BOX 1544|      TUCSON|   AZ|85702-1544| 0000|        03|          3|          2000|200605|            1|        15|000000000|           5|    01|    202405|       0|        0|           02|               0|     05|        0|         0|          0|    O50|                NULL|\n",
      "|208961711|STRAIGHT TRUTH AB...|       % TOM WADKINS|        PO BOX 64507|      TUCSON|   AZ|85728-4507| 0000|        03|          3|          1000|200801|            1|        15|000000000|           1|    01|    202312|       5|        4|           01|               0|     12|   714263|    280683|     268210|   B990|                NULL|\n",
      "|205912013| KNIGHTS OF COLUMBUS|    % RAYMOND FARLEY|  6116 E ONERLOOK LN|        YUMA|   AZ|85365-0000| 0188|        08|          9|          1000|194010|            1|        00|036029265|           5|    01|    202212|       0|        0|           02|               0|     12|        0|         0|          0|   NULL|14157 FR JAMES TI...|\n",
      "|237172414|CATHOLIC DAUGHTER...|% MRS RUTH HEFFERNAN|         803 RUTH ST|    PRESCOTT|   AZ|86301-1920| 0928|        03|          9|          1700|194603|            1|        15|036029279|           5|    01|      NULL|       1|        1|           13|               0|     12|     NULL|      NULL|       NULL|   NULL|                 311|\n",
      "|332307098|HINDU CULTURAL ED...|                NULL|1989 W ELLIOT RD ...|    CHANDLER|   AZ|85224-8817| 0000|        03|          3|          1270|202501|            1|        15|000000000|           1|    01|      NULL|       0|        0|           02|               0|     12|     NULL|      NULL|       NULL|    A20|                HCEC|\n",
      "|273160783|TELUGU CHRISTIAN ...|                NULL|     24730 N 29TH PL|     PHOENIX|   AZ|85024-6242| 7198|        03|          9|          7000|199407|            1|        10|000000000|           1|    01|      NULL|       0|        0|           06|               0|     07|     NULL|      NULL|       NULL|   NULL|                NULL|\n",
      "|202959364|DESERT ESPERANZA INC|                NULL|202 E EARLL DR ST...|     PHOENIX|   AZ|85012-2647| 0000|        03|          3|          1000|200512|            1|        15|000000000|           0|    01|    202309|       5|        3|           01|               0|     09|   846409|     88999|      88999|    L21|                NULL|\n",
      "|260072366|LA MISION DE LAS ...|      % LILY ESTRADA|        161 W ELY LN|    AVONDALE|   AZ|85323-2254| 1678|        03|          9|          7000|196408|            1|        10|001002029|           5|    01|      NULL|       0|        0|           06|               0|     12|     NULL|      NULL|       NULL|   NULL|LA MISION DE LAS ...|\n",
      "+---------+--------------------+--------------------+--------------------+------------+-----+----------+-----+----------+-----------+--------------+------+-------------+----------+---------+------------+------+----------+--------+---------+-------------+----------------+-------+---------+----------+-----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM my_catalog.nonprofit_data_explorer.bmo_table\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
